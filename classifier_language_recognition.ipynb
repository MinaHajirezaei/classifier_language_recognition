{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "classifier_language_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_A_yHNDZ9eZ"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUW7_aScZ9es"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "from sklearn.preprocessing import LabelEncoder "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zppUBi0cZ9ew",
        "outputId": "3b16dd09-6738-453c-f41d-e6a2698599a3"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ys64XXXXbENN",
        "outputId": "a4a7270c-4f15-4e03-fe54-d728efe6cfd0"
      },
      "source": [
        "!unzip comments.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  comments.zip\n",
            "  inflating: comments.csv            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dnBIILuEZ9e3",
        "outputId": "e0bbd4c9-1b35-4a4f-cc7a-f6fd137561f1"
      },
      "source": [
        "train_df = pd.read_csv(\"comments.csv\", header=None)\n",
        "train_df.columns = ['sentence', 'language']\n",
        "train_df.tail()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>58086</th>\n",
              "      <td>وفی المفید  ولا یستنجی فی حیاض علی طریق المسلم...</td>\n",
              "      <td>arabic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58087</th>\n",
              "      <td>قوله    کبیع الخیار    اعترض بان المعتمد ان ال...</td>\n",
              "      <td>arabic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58088</th>\n",
              "      <td>وقال محمد  یحنث قاسه علی صدیق فلان وزوجه فلان ...</td>\n",
              "      <td>arabic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58089</th>\n",
              "      <td>والثانی  انه لو کان فی مال زوجه تبسط لسقط عنه ...</td>\n",
              "      <td>arabic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58090</th>\n",
              "      <td>الا تری انه بعد السبی قبل العتق کان الحکم هکذا...</td>\n",
              "      <td>arabic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                sentence language\n",
              "58086  وفی المفید  ولا یستنجی فی حیاض علی طریق المسلم...   arabic\n",
              "58087  قوله    کبیع الخیار    اعترض بان المعتمد ان ال...   arabic\n",
              "58088  وقال محمد  یحنث قاسه علی صدیق فلان وزوجه فلان ...   arabic\n",
              "58089  والثانی  انه لو کان فی مال زوجه تبسط لسقط عنه ...   arabic\n",
              "58090  الا تری انه بعد السبی قبل العتق کان الحکم هکذا...   arabic"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UuBFMpJZ9e6",
        "outputId": "13670572-0300-4f37-9957-4c745b9d278f"
      },
      "source": [
        "train_df.language.value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "arabic     52736\n",
              "persian     1722\n",
              "spanish      966\n",
              "italian      963\n",
              "french       868\n",
              "english      836\n",
              "Name: language, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OyvsRhHZ9e9",
        "outputId": "e41a85a6-7963-4fb3-8683-679ebf8d0d00"
      },
      "source": [
        "train_df.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58091, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1h4fD-BZ9fA"
      },
      "source": [
        "train_df['sentence_lower'] = train_df[\"sentence\"].str.lower()\n",
        "train_df['sentence_no_punctuation'] = train_df['sentence_lower'].str.replace('[^\\w\\s]','')\n",
        "train_df['sentence_no_punctuation'] = train_df[\"sentence_no_punctuation\"].fillna(\"fillna\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56eUQVSGZ9fC",
        "outputId": "102779f5-142a-498d-8d1b-19d767f54802"
      },
      "source": [
        "len(train_df) #we print the length, not a big one but sufficient"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58091"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwH4LH2AZ9fG",
        "outputId": "bac1f474-8ea0-4076-eb78-2cea170cface"
      },
      "source": [
        "num_classes = len(train_df.language.unique())\n",
        "num_classes"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAT8_MXFZ9fK",
        "outputId": "3080f259-8206-4c55-824b-3ff2ec3cf282"
      },
      "source": [
        "Y = train_df['language']\n",
        "encoder = LabelEncoder()\n",
        "Y = encoder.fit_transform(Y)\n",
        "Y"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LOECPuNZ9fM",
        "outputId": "63b562fd-9213-4fc1-ce08-9a4744cbfa8b"
      },
      "source": [
        "Y = tf.keras.utils.to_categorical(\n",
        "    Y,\n",
        "    num_classes = num_classes\n",
        ")\n",
        "Y"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [1., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joE_Dy-YZ9fO"
      },
      "source": [
        "max_features = 5000 #we set maximum number of words to 5000\n",
        "maxlen = 400 #we set maximum sequence length to 400"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZDSunntZ9fQ"
      },
      "source": [
        "tok = tf.keras.preprocessing.text.Tokenizer(num_words = max_features)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPzInDnuZ9fR"
      },
      "source": [
        "tok.fit_on_texts(list(train_df['sentence_no_punctuation'])) #fit to cleaned text"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbOE-44PZ9fR",
        "outputId": "58406312-2287-43ab-b526-836759393913"
      },
      "source": [
        "len(tok.word_index)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "183763"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34kkZl5CZ9fS"
      },
      "source": [
        "vocab_size = len(tok.word_index) + 1 \n",
        "#this represents the number of words that we tokenize different from max_features but necessary for\n",
        "#the definition of the dimension of the embedding space"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Bm3iwAESZ9fU",
        "outputId": "72236cdf-652d-428f-ade8-643af3a674a0"
      },
      "source": [
        "train_df.loc[0, 'sentence']"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Jean Beauverie (Fontaines-sur-Saône, 18 febbraio 1874 – Lione, 22 febbraio 1938) è stato un botanico e micologo francese.'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pWZJ0RiZ9fV"
      },
      "source": [
        "train_df = tok.texts_to_sequences(list(train_df['sentence_no_punctuation'])) "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLKq1GZ1Z9fW",
        "outputId": "005efb6a-a107-4253-c40f-e3a1d9dab034"
      },
      "source": [
        "train_df[0]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[639, 1110, 168, 1025, 87, 173, 3572]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz5y-yYUZ9fX"
      },
      "source": [
        "train_df = tf.keras.preprocessing.sequence.pad_sequences(train_df,\n",
        "                                                         maxlen = maxlen,\n",
        "                                                         padding='pre') "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-t6_8F0Z9fX"
      },
      "source": [
        "train_df[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE5Cx162Z9fY"
      },
      "source": [
        "from sklearn.model_selection import train_test_split #divide into train and test set"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X54-NvzOZ9fZ"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_df, Y, test_size=0.1, random_state=42)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT-HxmPgZ9fa"
      },
      "source": [
        "embedding_dim = 50"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjN73aM2Z9fb"
      },
      "source": [
        "Let's write down the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scfFR0fTZ9fd"
      },
      "source": [
        "+ input_dim: Integer. Size of the vocabulary, i.e. maximum integer index + 1.\n",
        "+ output_dim: Integer. Dimension of the dense embedding.\n",
        "+ input_length: Length of input sequences, when it is constant. This argument is required if you are going to connect Flatten then Dense layers upstream (without it, the shape of the dense outputs cannot be computed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbVpMDnjZ9fd"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Embedding(input_dim = vocab_size,\n",
        "                            output_dim = embedding_dim,\n",
        "                            input_length = maxlen),\n",
        "  tf.keras.layers.Flatten(), \n",
        "  tf.keras.layers.Dense(num_classes, activation = 'softmax')\n",
        "])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYXbJK3WZ9fe"
      },
      "source": [
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZms8-RmZ9ff",
        "outputId": "3784a2f2-e46e-4fdd-c396-15b6132d8eff"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 400, 50)           9188200   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 20000)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 120006    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,308,206\n",
            "Trainable params: 9,308,206\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWMTn4lzZ9ff",
        "outputId": "5ae1565e-96cc-4266-9c47-b45f05b257fb"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=3)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1634/1634 [==============================] - 200s 122ms/step - loss: 0.0525 - accuracy: 0.9873\n",
            "Epoch 2/3\n",
            "1634/1634 [==============================] - 199s 122ms/step - loss: 0.0056 - accuracy: 0.9988\n",
            "Epoch 3/3\n",
            "1634/1634 [==============================] - 198s 121ms/step - loss: 0.0044 - accuracy: 0.9990\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efe27612090>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xReyI6WOZ9fg",
        "outputId": "2cacdb8c-8179-4330-81f2-91facf01187c"
      },
      "source": [
        "model.evaluate(X_test, y_test, verbose = 0) "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.007759384345263243, 0.9982788562774658]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEV06lRHZ9fg"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X0xdUXDZ9fg"
      },
      "source": [
        "predictions = model.predict(X_test) \n",
        "cm = confusion_matrix(predictions.argmax(axis=1), y_test.argmax(axis=1))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tRGLglDZ9fh"
      },
      "source": [
        "cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsmEM8jXZ9fi",
        "outputId": "b9c75b15-6983-4f19-f724-af074f88fb37"
      },
      "source": [
        "print('english', encoder.transform(['english']))\n",
        "print('french', encoder.transform(['french']))\n",
        "print('persian', encoder.transform(['persian']))\n",
        "print('italian', encoder.transform(['italian']))\n",
        "print('spanish', encoder.transform(['spanish']))\n",
        "print('arabic', encoder.transform(['arabic']))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "english [1]\n",
            "french [2]\n",
            "persian [4]\n",
            "italian [3]\n",
            "spanish [5]\n",
            "arabic [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPrJax3nZ9fj"
      },
      "source": [
        "In this experiment we will predict the language of the same sentence in the different languages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moPY4ONwZ9fj"
      },
      "source": [
        "new_text = [\"tensorflow is a great tool you can find a lot of tutorials from\"]\n",
        "#new_text = [\"tensorflow est un excellent outil vous pouvez trouver beaucoup de tutoriels de\"]\n",
        "#new_text = [\"tensorflow è un ottimo strumento puoi trovare molti tutorial di\"]\n",
        "#new_text = [\"tensorflow es una gran herramienta puedes encontrar muchos tutoriales de\"]\n",
        "# new_text = [\"توی یک آموزش تقریبا ده ساعته تلاش کردم 6تا سناریو واقعی تعریف کنم و بعد پیاده سازی انجام بشه. لیست پروژه هایی که توی این دوره پیاده سازی شدند\"]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmO-vS5rZ9fk"
      },
      "source": [
        "test_text = tok.texts_to_sequences(new_text)\n",
        "test_text = tf.keras.preprocessing.sequence.pad_sequences(test_text, maxlen = maxlen)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xALcGKkBZ9fk",
        "outputId": "cc71aaa9-db04-49ca-d177-9197f86925a6"
      },
      "source": [
        "predictions = model.predict(test_text)\n",
        "print(predictions.argmax())\n",
        "print(predictions)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "[[1.45731028e-05 9.99758303e-01 2.00727700e-05 1.11691275e-04\n",
            "  5.70292941e-05 3.83737824e-05]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5SIHVpCZ9fl"
      },
      "source": [
        "def lang_detector(txt):\n",
        "    tmp = tok.texts_to_sequences(txt)\n",
        "    tmp = tf.keras.preprocessing.sequence.pad_sequences(tmp, maxlen = maxlen)\n",
        "    prediction = model.predict(tmp)\n",
        "    label = prediction.argmax()\n",
        "    prediction = encoder.inverse_transform([label])\n",
        "    print(txt, prediction)    "
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_yv-FJIZ9fl",
        "outputId": "f2dc2fc0-a182-4323-e7bd-07562e878758"
      },
      "source": [
        "# tmp_txt = ['در این ویدئو با ضرورت یادگیری پردازش متون فارسی با پایتون آشنا شویم']\n",
        "tmp_txt = ['الحمدالله رب العالمین و صلی الله علی سیدنا محمد و آله الطاهرین و اعنه الله علی اعدئهم اجمعین']\n",
        "lang_detector(tmp_txt)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['الحمدالله رب العالمین و صلی الله علی سیدنا محمد و آله الطاهرین و اعنه الله علی اعدئهم اجمعین'] ['arabic']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKfBkR4oZ9fm",
        "outputId": "139dec9c-13a7-4d1c-ce3e-1de15a0fa859"
      },
      "source": [
        "tmp_txt = ['النّاس عَبيدُ الدّنيا، و الدّين لَعِق (7) على اَلسِنَتِهم، يحوطُونَهُ ما درَّت معايشُهُم، فاذا مُحِّصوا بالبلأ قَلَّ الدَّيَّانون .']\n",
        "lang_detector(tmp_txt)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['النّاس عَبيدُ الدّنيا، و الدّين لَعِق (7) على اَلسِنَتِهم، يحوطُونَهُ ما درَّت معايشُهُم، فاذا مُحِّصوا بالبلأ قَلَّ الدَّيَّانون .'] ['arabic']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adDqdchBer1G",
        "outputId": "48af2146-a30e-49ef-f39e-62935e179e6c"
      },
      "source": [
        "tmp_txt = ['«ما در روزهاى آغازين ظهور دين همراه با رسول اللّه صلى اللّه عليه و آله و سلم، دست به شمشير مى‌برديم و پدر، فرزند، برادر و عموهايمان را مى‌كشتيم، اما اين قتل و كشتار ارحام و نزديكان تنها باعث تقويت ايمان و ثبات قدم، در اعتقاداتمان مى‌شد».']\n",
        "lang_detector(tmp_txt)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['«ما در روزهاى آغازين ظهور دين همراه با رسول اللّه صلى اللّه عليه و آله و سلم، دست به شمشير مى\\u200cبرديم و پدر، فرزند، برادر و عموهايمان را مى\\u200cكشتيم، اما اين قتل و كشتار ارحام و نزديكان تنها باعث تقويت ايمان و ثبات قدم، در اعتقاداتمان مى\\u200cشد».'] ['persian']\n"
          ]
        }
      ]
    }
  ]
}